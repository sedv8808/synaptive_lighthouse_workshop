{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lighthouse Labs - Synaptive Medical\n",
    "\n",
    "### W7D7 Deep Learning and Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Instructor: Socorro Dominguez  \n",
    "January 15, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda:**\n",
    "- What kind of layers CNN have?\n",
    "    - Convolution\n",
    "    - Pooling\n",
    "    - Flattening\n",
    "    - Full connection\n",
    "     \n",
    "- Case Studies of different CNN algorithms. \n",
    "\n",
    "- CNN tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "![img](img/CNNnews.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ".... not that CNN....\n",
    "\n",
    "This CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![img](img/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CNNs most common task is Computer Vision.\n",
    "\n",
    "* Sports:\n",
    "    * Player Tracking\n",
    "    * Ball Tracking\n",
    "\n",
    "* Health and Medicine:\n",
    "    * Cancer / Tumor Detection\n",
    "    * Cell Classification\n",
    "    * Movement Analysis for neurological and musculoskeletal diseases\n",
    "\n",
    "* Agriculture and farming:\n",
    "    * Plant Recognition.\n",
    "    * Farm Automation\n",
    "    * Animal Monitoring\n",
    "\n",
    "* Transportation,  Oiling and mining, many others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convolutional Neural Networks are a type of Deep Learning Algorithm.\n",
    "\n",
    "1. CNNs take an image as an input.\n",
    "2. CNNs learn the features of the image through filters. \n",
    "3. They identify important objects present in the image, allowing them to learn to discern one image from the other.\n",
    "\n",
    "In our walkthrough, the CNN will learn specific features of cats that differentiate them from the dogs. \n",
    "Then, when it is provided input of cats and dogs, it can differentiate between the two. \n",
    "\n",
    "! During cold-start, the filters \"require\" hand engineering but with progress in training, they are able to adapt to the learned features and develop filters of their own. CNNs are continuously evolving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/robot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* CNNs output is usually probabilities of being something. \n",
    "\n",
    "* A CNN is a special tries to reduce the number of parameters in a deep neural network with many units without losing too much in the quality of the model. \n",
    "\n",
    "* In images, pixels that are close to one another usually have the same type of information: sky, water, leaves, etc. \n",
    "\n",
    "* The exception from the rule are **the edges**: the parts of an image where two different objects “touch” one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The neural network is trained to recognize regions of the same information as well as the edges. This would allow to predict the object represented in the image. \n",
    "\n",
    "* **Example:** If the neural network detected multiple skin regions and edges that look like parts of an oval with skin-like tone on the inside and bluish tone on the outside, then it is likely that it’s a face on a sky background. \n",
    "    * If the goal is to detect people on pictures, the neural network will most likely succeed in predicting a person in this picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The most important information in the image is local**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does a CNN work?\n",
    "- We split the image into square patches using a moving window approach. \n",
    "- We can train multiple smaller regression models at once, each regression model receives a square patch as input.\n",
    "    - We train the 'filters'.\n",
    "- Each regression model's work is to learn to detect a specific kind of pattern in the input patch. \n",
    "\n",
    "For example, one small regression model will learn to detect the sky; another one will detect the grass, the third one will detect edges of a building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CNNs perform similarly to an ordinary fully connected Neural Networks. \n",
    "    * They have weights and biases that are learned from the input and biases. \n",
    "    * Every neuron connected in the network receives an input and performs a dot product on it. \n",
    "    * There is a function at the end that consists of scores that we obtain from the various layers. \n",
    "    * They have a loss function at the end to evaluate performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/anatomyofcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What seems different\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first architecture is more practical manner. \n",
    "\n",
    "There is no linear arrangement of neurons. CNN's neurons have a structure of three dimensions – Length, Width, and Height. \n",
    "\n",
    "For instance, Dogs and Cats images are dimensions 32x32x3 and the final output will have a singular vector of the images of dimensions 1x1x2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/3channels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The goal:  Reduce the images into an easier form to process, without losing features which are critical for getting a good prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**ARCHITECTURE**\n",
    "\n",
    "* INPUT – A typical image dataset will hold images if dimensions l x w x d, where the depth denotes the number of channels (RGB) in the image.\n",
    "  \n",
    "  \n",
    "* CONV layer - computes the dot product between the weights of the neuron and the region of the input image to which share a connection. An example would be 32x32x12 denoting the 12 filters which the neural network makes use of.\n",
    "  \n",
    "  \n",
    "* The third layer consists of RELU which (activation function) to our resultant dot product. \n",
    "  \n",
    "  \n",
    "* The fourth layer is a POOLing layer, it downsamples the spatial dimensions of the image (width and height).\n",
    "  \n",
    "  \n",
    "* The fully connected layer will compute the class score, leading to a final volume of 1 x 1 x n; where n is the number of categories to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The convolutional component comprises the learnable filter.  \n",
    "\n",
    "* To detect some pattern, a small regression model has to learn the parameters of a matrix F (for “filter”) of size p × p, where p is the size of a patch.\n",
    "\n",
    "\n",
    "* If we had for input a black and white image, 1 would represent the black and 0 would represent the white pixels. \n",
    "* Assume 3x3 pixels patches (p = 3). Some patch could then look like the following matrix P (for “patch”):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P = \\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The previous patch represents a pattern that looks like a cross. \n",
    "\n",
    "The small regression model that will detect such patterns (and only them) would need to learn a 3 by 3 parameter matrix F where parameters at positions corresponding to the 1s in the input patch would be positive numbers, while the parameters in positions corresponding to 0s would be close to zero. \n",
    "\n",
    "If we calculate the convolution of matrices P and F, the value we obtain is higher the more similar F is to P. To illustrate the convolution of two matrices, assume that F looks like this:\n",
    "\n",
    "$$F = \\begin{bmatrix} 0 & 2 & 3 \\\\ 2 & 4 & 1 \\\\ 0 & 3 & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then convolution operator is only defined for matrices that have the same number of rows and columns. For our matrices of P and F it’s calculated as illustrated below:\n",
    "\n",
    "![convolution](img/02_Convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If our patch had a different pattern, then the convolution with F would give a different result. \n",
    "\n",
    "*The more the patch “looks” like the filter, the higher the value of the convolution operation is*\n",
    "\n",
    "For convenience, there’s also a bias parameter b associated with each filter F which is added to the result of a\n",
    "convolution before applying the nonlinearity (activation function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One layer of a CNN consists of multiple convolution filters (each with its own bias parameter).\n",
    "\n",
    "Each filter of the first layer slides — or convolves — across the input image, left to right, top to bottom, and convolution is computed at each iteration.\n",
    "\n",
    "Like this:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the CNN has one convolution layer following another convolution layer, then the subsequent layer *l + 1* treats the output of the preceding layer *l* as a collection of size *l* image matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Pooling**\n",
    "\n",
    "This is a technique very often used in CNNs. Pooling works in a way very similar to convolution, as a filter applied using amoving window approach. \n",
    "\n",
    "Instead of applying a trainable filter to an input matrix, a pooling layer applies a fixed operator, usually either max or average. \n",
    "\n",
    "Pooling's hyperparameters are also the size of the filter and the stride. \n",
    "\n",
    "Usually, a pooling layer follows a convolution layer, and it gets the output of convolution as input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pooling does not have parameters to learn. It also contributes to the increased accuracy of the model and improves the speed of training by reducing the number of parameters of the neural network.\n",
    "![pooling](https://miro.medium.com/max/792/1*uoWYsCV5vBU8SHFPAPao-w.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why ReLU as Normalization Technique\n",
    "\n",
    "After getting the new convolved matrix, anything negative is turned to zero.\n",
    "\n",
    "This removes unnecessary noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hyperparameters:\n",
    "* **Stride** Choose how big you want the step to be for the pooling, conv layers\n",
    "* **Padding** Add zeros around the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What a CNN looks like after all?\n",
    "\n",
    "![img](img/05_FullCNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![img](img/mnistcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Implementing Example in Keras**   \n",
    "\n",
    "We'll move on to the famous the MNIST digits -- a classic dataset for deep learning. The MNIST data set is  bigger than the digits dataset built into sklearn: the images are larger ($28\\times28$ instead of $8\\times8$) and there are more of them ($70000$ insetad of $1797$). In total, we're dealing with $70000\\times28\\times28\\approx 55$ million training pixels instead of $1797\\times8\\times8\\approx80000$ training pixels (about $500$ times more data). \n",
    "\n",
    "The following code loads the MNIST dataset. The first time you run it, the data will be downloaded. In future times, it will use the local version.\n",
    "\n",
    "*Close presentation view*\n",
    "\n",
    "\n",
    "Also check FMNIST Fashion Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this video to understand more: https://www.youtube.com/watch?v=FmpDIaiMIeA&feature=emb_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
