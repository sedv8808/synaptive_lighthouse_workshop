{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is **Grid Search**?  \n",
    "\n",
    "Grid search is used for hyperparameter tuning. It helps us determine the optimal values for a given model.  \n",
    "This is important as the performance of the entire model is based on the specified parameter and hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets, svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the steps in the Walkthrough\n",
    "  \n",
    "**Create Two Toy Datasets**  \n",
    "In the code below, we load the [digits dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html) , which contains **64 feature** variables. Each feature denotes the darkness of a pixel in an 8 by 8 image of a handwritten digit. We can see these features for the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digit data\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "        15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "        12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "         0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "        10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the features of the first observation\n",
    "digits.data[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **target** for this dataset is a vector containing the image’s true digit. For example, *the first observation* is a handwritten digit for ‘0’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the target of the first observation\n",
    "digits.target[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to demonstrate how **Cross Validation** and **parameter tuning** work, we need to  divide the digit data into two datasets called `data1` and `data2`. `data1` contains the first 1000 rows of the digits data, while `data2` contains the remaining ~800 rows. \n",
    "\n",
    "**Note that** this split is separate to the cross validation we will conduct and is done purely to demonstrate something at the end of the tutorial. In other words, don’t worry about `data2` for now, we will come back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset 1\n",
    "data1_features = digits.data[:1000]\n",
    "data1_target = digits.target[:1000]\n",
    "\n",
    "# Create dataset 2\n",
    "data2_features = digits.data[1000:]\n",
    "data2_target = digits.target[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Parameter Candidates**   \n",
    "\n",
    "Before looking which combination of parameter values produces the **most accurate** model, we must specify the *different candidate values* we want to try.   \n",
    "\n",
    "\n",
    "In the code below we have a number of candidate parameter values, including four different values for C (1, 10, 100, 1000), two values for gamma (0.001, 0.0001), and two kernels (linear, rbf). The grid search will try all combinations of parameter values and select the set of parameters which provides the most accurate model.\n",
    "\n",
    "*This might take a while if you have a lot of candidates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your `parameter grid`, you can conduct **Grid Search** to help you find **parameters** that produce the highest score.  \n",
    "  \n",
    "\n",
    "We can use **scikit-learn’s GridSearchCV** (Grid search Cross Validation). GridSearchCV’s Cross Validation uses 3-KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "                         {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "\n",
    "# n_jobs=Number of jobs to run in parallel. \n",
    "# None means 1\n",
    "# -1 means using all processors\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf.fit(data1_features, data1_target)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We have our results! First, let’s look at the accuracy score when we apply the model to the data1’s test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data1: 0.966\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for data1:', clf.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parameters are the best? We can tell scikit-learn to display them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 10\n",
      "Best Kernel: rbf\n",
      "Best Gamma: 0.001\n"
     ]
    }
   ],
   "source": [
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',clf.best_estimator_.C) \n",
    "print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check Using Second Dataset**  \n",
    "\n",
    "Remember the `second dataset` we created?  \n",
    "\n",
    "Now we will use it to prove that those parameters are actually used by the model. \n",
    "\n",
    "1. First, let's apply the classifier we just trained to the second dataset. \n",
    "\n",
    "2. Then we will train a new SVM classifier using the best parameters found in the `Grid Search`. \n",
    "\n",
    "We should get the same results for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698870765370138"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier trained using data1 to data2, and view the accuracy score\n",
    "clf.score(data2_features, data2_target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698870765370138"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a new classifier using the best parameters found by the grid search\n",
    "svm.SVC(C=10, kernel='rbf', gamma=0.001).fit(data1_features, data1_target).score(data2_features, data2_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
